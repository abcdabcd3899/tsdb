--
-- Basic tests for masteronly table
--
create schema masteronly;
set search_path to masteronly;
---------
-- INSERT
---------
create table foo (x int, y int) distributed masteronly;
create table foo1(like foo) distributed masteronly;
create table bar (like foo) distributed randomly;
create table bar1 (like foo) distributed by (x);
-- values --> masteronly table
-- random partitioned table --> masteronly table
-- hash partitioned table --> masteronly table
-- singleQE --> masteronly table
-- masteronly --> masteronly table
insert into bar values (1, 1), (3, 1);
insert into bar1 values (1, 1), (3, 1);
insert into foo1 values (1, 1), (3, 1);
insert into foo select * from bar;
insert into foo select * from bar1;
insert into foo select * from bar order by x limit 1;
insert into foo select * from foo;
select gp_segment_id, * from foo order by x;
 gp_segment_id | x | y 
---------------+---+---
            -1 | 1 | 1
            -1 | 1 | 1
            -1 | 1 | 1
            -1 | 1 | 1
            -1 | 1 | 1
            -1 | 1 | 1
            -1 | 3 | 1
            -1 | 3 | 1
            -1 | 3 | 1
            -1 | 3 | 1
(10 rows)

select bar.x, bar.y from bar, (select * from foo) as t1 order by 1,2;
 x | y 
---+---
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 1 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
 3 | 1
(20 rows)

select bar.x, bar.y from bar, (select * from foo order by x limit 1) as t1 order by 1,2;
 x | y 
---+---
 1 | 1
 3 | 1
(2 rows)

truncate foo;
truncate foo1;
truncate bar;
truncate bar1;
-- masteronly table --> random partitioned table
-- masteronly table --> hash partitioned table
insert into foo values (1, 1), (3, 1);
insert into bar select * from foo order by x limit 1;
insert into bar1 select * from foo order by x limit 1;
select gp_segment_id, * from foo order by x;
 gp_segment_id | x | y 
---------------+---+---
            -1 | 1 | 1
            -1 | 3 | 1
(2 rows)

-- select * from bar order by x;
-- select * from bar1 order by x;
drop table if exists foo;
drop table if exists foo1;
drop table if exists bar;
drop table if exists bar1;
--
-- CREATE UNIQUE INDEX
--
-- create unique index on non-distributed key.
create table foo (x int, y int) distributed masteronly;
create table bar (x int, y int) distributed randomly;
-- success
create unique index foo_idx on foo (y);
-- should fail
create unique index bar_idx on bar (y);
ERROR:  UNIQUE and DISTRIBUTED RANDOMLY are incompatible
drop table if exists foo;
drop table if exists bar;
--
-- CREATE TABLE with both PRIMARY KEY and UNIQUE constraints
--
create table foo (id int primary key, name text unique) distributed masteronly;
-- success
insert into foo values (1,'aaa');
insert into foo values (2,'bbb');
-- fail
insert into foo values (1,'ccc');
ERROR:  duplicate key value violates unique constraint "foo_pkey"
DETAIL:  Key (id)=(1) already exists.
insert into foo values (3,'aaa');
ERROR:  duplicate key value violates unique constraint "foo_name_key"
DETAIL:  Key (name)=(aaa) already exists.
drop table if exists foo;
--
-- CREATE TABLE
--
--
-- Like
CREATE TABLE parent (
        name            text,
        age                     int4,
        location        point
) distributed masteronly;
CREATE TABLE child (like parent) distributed masteronly;
CREATE TABLE child1 (like parent) DISTRIBUTED BY (name);
CREATE TABLE child2 (like parent);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'name' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
-- should be masteronly table
\d child
              Table "masteronly.child"
  Column  |  Type   | Collation | Nullable | Default 
----------+---------+-----------+----------+---------
 name     | text    |           |          | 
 age      | integer |           |          | 
 location | point   |           |          | 
Distributed by: DISTRIBUTED MASTERONLY

-- should distributed by name
\d child1
              Table "masteronly.child1"
  Column  |  Type   | Collation | Nullable | Default 
----------+---------+-----------+----------+---------
 name     | text    |           |          | 
 age      | integer |           |          | 
 location | point   |           |          | 
Distributed by: (name)

-- should be masteronly table
\d child2
              Table "masteronly.child2"
  Column  |  Type   | Collation | Nullable | Default 
----------+---------+-----------+----------+---------
 name     | text    |           |          | 
 age      | integer |           |          | 
 location | point   |           |          | 
Distributed by: (name)

drop table if exists parent;
drop table if exists child;
drop table if exists child1;
drop table if exists child2;
-- Inherits
CREATE TABLE parent_om (
        name            text,
        age                     int4,
        location        point
) distributed masteronly;
CREATE TABLE parent_part (
        name            text,
        age                     int4,
        location        point
) distributed by (name);
-- inherits from a masteronly table, should fail
CREATE TABLE child (
        salary          int4,
        manager         name
) INHERITS (parent_om);
ERROR:  cannot inherit from catalog table "parent_om" to create table "child"
DETAIL:  An inheritance hierarchy cannot contain a mixture of distributed and non-distributed tables.
-- masteronly table can not have parents, should fail
CREATE TABLE child (
        salary          int4,
        manager         name
) INHERITS (parent_part) DISTRIBUTED MASTERONLY;
drop table if exists parent_om;
drop table if exists parent_part;
ERROR:  cannot drop table parent_part because other objects depend on it
DETAIL:  table child depends on table parent_part
HINT:  Use DROP ... CASCADE to drop the dependent objects too.
drop table if exists child;
--
-- CTAS
--
-- CTAS from generate_series
create table foo as select i as c1, i as c2
from generate_series(1,3) i distributed masteronly;
-- CTAS from masteronly table
create table bar as select * from foo distributed masteronly;
select count(*) from bar;
 count 
-------
     3
(1 row)

drop table if exists foo;
drop table if exists bar;
-- CTAS from partition table table
create table foo as select i as c1, i as c2
from generate_series(1,3) i;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
create table bar as select * from foo distributed masteronly;
select count(*) from bar;
 count 
-------
     3
(1 row)

drop table if exists foo;
drop table if exists bar;
-- CTAS from singleQE
create table foo as select i as c1, i as c2
from generate_series(1,3) i;
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column(s) named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
select * from foo;
 c1 | c2 
----+----
  2 |  2
  3 |  3
  1 |  1
(3 rows)

create table bar as select * from foo order by c1 limit 1 distributed masteronly;
select count(*) from bar;
 count 
-------
     1
(1 row)

drop table if exists foo;
drop table if exists bar;
-- Create view can work
create table foo(x int, y int) distributed masteronly;
insert into foo values(1,1);
create view v_foo as select * from foo;
select * from v_foo;
 x | y 
---+---
 1 | 1
(1 row)

drop view v_foo;
drop table if exists foo;
---------
-- Alter
--------
-- Drop distributed key column
create table foo(x int, y int) distributed masteronly;
create table bar(like foo) distributed by (x);
insert into foo values(1,1);
insert into bar values(1,1);
-- success
alter table foo drop column x;
-- fail
alter table bar drop column x;
NOTICE:  dropping a column that is part of the distribution policy forces a NULL distribution policy
drop table if exists foo;
drop table if exists foo1;
NOTICE:  table "foo1" does not exist, skipping
drop table if exists bar;
drop table if exists bar1;
NOTICE:  table "bar1" does not exist, skipping
-- Alter gp_distribution_policy
create table foo(x int, y int) distributed masteronly;
create table foo1(x int, y int) distributed masteronly;
create table bar(x int, y int) distributed by (x);
create table bar1(x int, y int) distributed randomly;
insert into foo select i,i from generate_series(1,10) i;
insert into foo1 select i,i from generate_series(1,10) i;
insert into bar select i,i from generate_series(1,10) i;
insert into bar1 select i,i from generate_series(1,10) i;
-- alter distribution policy of masteronly table
alter table foo set distributed by (x);
ERROR:  SET DISTRIBUTED BY not supported on non-distributed tables
alter table foo1 set distributed randomly;
ERROR:  SET DISTRIBUTED BY not supported on non-distributed tables
-- alter a partitioned table to masteronly table
alter table bar set distributed masteronly;
ERROR:  not support alter DISTRIBUTED BY to MASTERONLY
alter table bar1 set distributed masteronly;
ERROR:  not support alter DISTRIBUTED BY to MASTERONLY
-- verify the new policies
\d foo
              Table "masteronly.foo"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Distributed by: DISTRIBUTED MASTERONLY

\d foo1
              Table "masteronly.foo1"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Distributed by: DISTRIBUTED MASTERONLY

\d bar
              Table "masteronly.bar"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Distributed by: (x)

\d bar1
              Table "masteronly.bar1"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Distributed randomly

-- verify the reorganized data
select * from foo;
 x  | y  
----+----
  1 |  1
  2 |  2
  3 |  3
  4 |  4
  5 |  5
  6 |  6
  7 |  7
  8 |  8
  9 |  9
 10 | 10
(10 rows)

select * from foo1;
 x  | y  
----+----
  1 |  1
  2 |  2
  3 |  3
  4 |  4
  5 |  5
  6 |  6
  7 |  7
  8 |  8
  9 |  9
 10 | 10
(10 rows)

select count(*) from bar;
 count 
-------
    10
(1 row)

select count(*) from bar1;
 count 
-------
    10
(1 row)

-- alter back
alter table foo set distributed masteronly;
ERROR:  SET DISTRIBUTED BY not supported on non-distributed tables
alter table foo1 set distributed masteronly;
ERROR:  SET DISTRIBUTED BY not supported on non-distributed tables
alter table bar set distributed by (x);
WARNING:  distribution policy of relation "bar" already set to (x)
HINT:  Use ALTER TABLE "bar" SET WITH (REORGANIZE=TRUE) DISTRIBUTED BY (x) to force redistribution
alter table bar1 set distributed randomly;
WARNING:  distribution policy of relation "bar1" already set to DISTRIBUTED RANDOMLY
HINT:  Use ALTER TABLE "bar1" SET WITH (REORGANIZE=TRUE) DISTRIBUTED RANDOMLY to force a random redistribution.
-- verify the policies again
\d foo
              Table "masteronly.foo"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Distributed by: DISTRIBUTED MASTERONLY

\d foo1
              Table "masteronly.foo1"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Distributed by: DISTRIBUTED MASTERONLY

\d bar
              Table "masteronly.bar"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Distributed by: (x)

\d bar1
              Table "masteronly.bar1"
 Column |  Type   | Collation | Nullable | Default 
--------+---------+-----------+----------+---------
 x      | integer |           |          | 
 y      | integer |           |          | 
Distributed randomly

-- verify the reorganized data again
select * from foo;
 x  | y  
----+----
  1 |  1
  2 |  2
  3 |  3
  4 |  4
  5 |  5
  6 |  6
  7 |  7
  8 |  8
  9 |  9
 10 | 10
(10 rows)

select * from foo1;
 x  | y  
----+----
  1 |  1
  2 |  2
  3 |  3
  4 |  4
  5 |  5
  6 |  6
  7 |  7
  8 |  8
  9 |  9
 10 | 10
(10 rows)

select count(*) from bar;
 count 
-------
    10
(1 row)

select count(*) from bar1;
 count 
-------
    10
(1 row)

drop table if exists foo;
drop table if exists foo1;
drop table if exists bar;
drop table if exists bar1;
---------
-- UPDATE / DELETE
---------
create table foo(x int, y int) distributed masteronly;
create table bar(x int, y int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'x' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
insert into foo values (1, 1), (2, 1);
insert into bar values (1, 2), (2, 2);
update foo set y = 2 where y = 1;
select * from foo;
 x | y 
---+---
 1 | 2
 2 | 2
(2 rows)

update foo set y = 1 from bar where bar.y = foo.y;
select * from foo;
 x | y 
---+---
 1 | 1
 2 | 1
(2 rows)

delete from foo where y = 1;
select * from foo;
 x | y 
---+---
(0 rows)

-- Test masteronly table within init plan
insert into foo values (1, 1), (2, 1);
select * from bar where exists (select * from foo);
 x | y 
---+---
 1 | 2
 2 | 2
(2 rows)

------
-- Test Current Of is disabled for masteronly table
------
begin;
declare c1 cursor for select * from foo;
fetch 1 from c1;
 x | y 
---+---
 1 | 1
(1 row)

delete from foo where current of c1;
abort;
begin;
declare c1 cursor for select * from foo;
fetch 1 from c1;
 x | y 
---+---
 1 | 1
(1 row)

update foo set y = 1 where current of c1;
abort;
-----
-- Test updatable view works for masteronly table
----
truncate foo;
truncate bar;
insert into foo values (1, 1);
insert into foo values (2, 2);
insert into bar values (1, 1);
create view v_foo as select * from foo where y = 1;
begin;
update v_foo set y = 2;
select * from gp_dist_random('foo');
 x | y 
---+---
(0 rows)

abort;
update v_foo set y = 3 from bar where bar.y = v_foo.y;
select * from gp_dist_random('foo');
 x | y 
---+---
(0 rows)

-- Test gp_segment_id for masteronly table
-- gp_segment_id is ambiguous for masteronly table, it's been disabled now.
create table baz (c1 int, c2 int) distributed masteronly;
create table qux (c1 int, c2 int);
NOTICE:  Table doesn't have 'DISTRIBUTED BY' clause -- Using column named 'c1' as the Greenplum Database data distribution key for this table.
HINT:  The 'DISTRIBUTED BY' clause determines the distribution of data. Make sure column(s) chosen are the optimal data distribution key to minimize skew.
select gp_segment_id from baz;
 gp_segment_id 
---------------
(0 rows)

select xmin from baz;
 xmin 
------
(0 rows)

select xmax from baz;
 xmax 
------
(0 rows)

select ctid from baz;
 ctid 
------
(0 rows)

select * from baz where c2 = gp_segment_id;
 c1 | c2 
----+----
(0 rows)

select * from baz, qux where baz.c1 = gp_segment_id;
ERROR:  column reference "gp_segment_id" is ambiguous
LINE 1: select * from baz, qux where baz.c1 = gp_segment_id;
                                              ^
update baz set c2 = gp_segment_id;
update baz set c2 = 1 where gp_segment_id = 1;
update baz set c2 = 1 from qux where gp_segment_id = baz.c1;
ERROR:  column reference "gp_segment_id" is ambiguous
LINE 1: update baz set c2 = 1 from qux where gp_segment_id = baz.c1;
                                             ^
insert into baz select i, i from generate_series(1, 1000) i;
vacuum baz;
vacuum full baz;
analyze baz;
-- Test dependencies check when alter table to masteronly table
create view v_qux as select ctid from qux;
alter table qux set distributed masteronly;
ERROR:  not support alter DISTRIBUTED BY to MASTERONLY
drop view v_qux;
alter table qux set distributed masteronly;
ERROR:  not support alter DISTRIBUTED BY to MASTERONLY
-- Test cursor for update also works for masteronly table
create table cursor_update (c1 int, c2 int) distributed masteronly;
insert into cursor_update select i, i from generate_series(1, 10) i;
begin;
declare c1 cursor for select * from cursor_update order by c2 for update;
fetch next from c1;
 c1 | c2 
----+----
  1 |  1
(1 row)

end;
-- Test MinMax path on masteronly table
create table minmaxtest (x int, y int) distributed masteronly;
create index on minmaxtest (x);
insert into minmaxtest select generate_series(1, 10);
set enable_seqscan=off;
select min(x) from minmaxtest;
 min 
-----
   1
(1 row)

-- Test masteronly on partition table
-- will crash by Assert
-- CREATE TABLE foopart (a int4, b int4) DISTRIBUTED MASTERONLY PARTITION BY RANGE (a) (START (1) END (10));
-- CREATE TABLE foopart (a int4, b int4) PARTITION BY RANGE (a) (START (1) END (10)) ;
-- should fail
-- ALTER TABLE foopart SET DISTRIBUTED MASTERONLY;
-- ALTER TABLE foopart_1_prt_1 SET DISTRIBUTED MASTERONLY;
-- DROP TABLE foopart;
-- Test that masteronly table can't inherit a parent table, and it also
-- can't be inherited by a child table.
-- 1. Replicated table can't inherit a parent table.
CREATE TABLE parent (t text) DISTRIBUTED BY (t);
-- This is not allowed: should fail
CREATE TABLE child () INHERITS (parent) DISTRIBUTED MASTERONLY;
CREATE TABLE child (t text) DISTRIBUTED MASTERONLY;
ERROR:  relation "child" already exists
-- should fail
ALTER TABLE child INHERIT parent;
ERROR:  relation "parent" would be inherited from more than once
DROP TABLE child, parent;
-- 2. Replicated table can't be inherited
CREATE TABLE parent (t text) DISTRIBUTED MASTERONLY;
-- should fail
CREATE TABLE child () INHERITS (parent) DISTRIBUTED MASTERONLY;
CREATE TABLE child () INHERITS (parent) DISTRIBUTED BY (t);
ERROR:  cannot inherit from catalog table "parent" to create table "child"
DETAIL:  An inheritance hierarchy cannot contain a mixture of distributed and non-distributed tables.
CREATE TABLE child (t text) DISTRIBUTED MASTERONLY;
ERROR:  relation "child" already exists
ALTER TABLE child INHERIT parent;
ERROR:  relation "parent" would be inherited from more than once
CREATE TABLE child2(t text) DISTRIBUTED BY (t);
ALTER TABLE child2 INHERIT parent;
DROP TABLE child, child2, parent;
-- volatile masteronly
-- General and segmentGeneral locus imply that if the corresponding
-- slice is executed in many different segments should provide the
-- same result data set. Thus, in some cases, General and segmentGeneral
-- can be treated like broadcast. But if the segmentGeneral and general
-- locus path contain volatile functions, they lose the property and
-- can only be treated as singleQE. The following cases are to check that
-- we correctly handle all these cases.
-- FIXME: ORCA does not consider this, we need to fix the cases when ORCA
-- consider this.
create table t_hashdist(a int, b int, c int) distributed by (a);
create table t_masteronly_volatile(a int, b int, c int) distributed masteronly;
---- pushed down filter
explain (costs off) select * from t_masteronly_volatile, t_hashdist where t_masteronly_volatile.a > random();
                              QUERY PLAN                              
----------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice2)
                     ->  Seq Scan on t_masteronly_volatile
                           Filter: ((a)::double precision > random())
 Optimizer: Postgres query optimizer
(8 rows)

-- join qual
explain (costs off) select * from t_hashdist, t_masteronly_volatile x, t_masteronly_volatile y where x.a + y.a > random();
                            QUERY PLAN                             
-------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   ->  Nested Loop
         Join Filter: (((x.a + y.a))::double precision > random())
         ->  Nested Loop
               ->  Seq Scan on t_hashdist
               ->  Materialize
                     ->  Broadcast Motion 1:3  (slice2)
                           ->  Seq Scan on t_masteronly_volatile x
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice3)
                     ->  Seq Scan on t_masteronly_volatile y
 Optimizer: Postgres query optimizer
(12 rows)

-- sublink & subquery
explain (costs off) select * from t_hashdist where a > All (select random() from t_masteronly_volatile);
                                     QUERY PLAN                                     
------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   ->  Nested Loop Left Anti Semi (Not-In) Join
         Join Filter: ((t_hashdist.a)::double precision <= "NotIn_SUBQUERY".random)
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice2)
                     ->  Subquery Scan on "NotIn_SUBQUERY"
                           ->  Seq Scan on t_masteronly_volatile
 Optimizer: Postgres query optimizer
(9 rows)

explain (costs off) select * from t_hashdist where a in (select random()::int from t_masteronly_volatile);
                           QUERY PLAN                            
-----------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   ->  Hash Join
         Hash Cond: (t_hashdist.a = ((random())::integer))
         ->  Seq Scan on t_hashdist
         ->  Hash
               ->  Redistribute Motion 1:3  (slice2)
                     Hash Key: ((random())::integer)
                     ->  HashAggregate
                           Group Key: (random())::integer
                           ->  Seq Scan on t_masteronly_volatile
 Optimizer: Postgres query optimizer
(11 rows)

-- subplan
explain (costs off, verbose) select * from t_hashdist left join t_masteronly_volatile on t_hashdist.a > any (select random() from t_masteronly_volatile);
                                                             QUERY PLAN                                                              
-------------------------------------------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   Output: t_hashdist.a, t_hashdist.b, t_hashdist.c, t_masteronly_volatile.a, t_masteronly_volatile.b, t_masteronly_volatile.c
   ->  Nested Loop Left Join
         Output: t_hashdist.a, t_hashdist.b, t_hashdist.c, t_masteronly_volatile.a, t_masteronly_volatile.b, t_masteronly_volatile.c
         Join Filter: ((SubPlan 1))
         ->  Seq Scan on masteronly.t_hashdist
               Output: t_hashdist.a, t_hashdist.b, t_hashdist.c, (SubPlan 1)
               SubPlan 1
                 ->  Materialize
                       Output: (random())
                       ->  Broadcast Motion 1:3  (slice2)
                             Output: (random())
                             ->  Seq Scan on masteronly.t_masteronly_volatile t_masteronly_volatile_1
                                   Output: random()
         ->  Materialize
               Output: t_masteronly_volatile.a, t_masteronly_volatile.b, t_masteronly_volatile.c
               ->  Broadcast Motion 1:3  (slice3)
                     Output: t_masteronly_volatile.a, t_masteronly_volatile.b, t_masteronly_volatile.c
                     ->  Seq Scan on masteronly.t_masteronly_volatile
                           Output: t_masteronly_volatile.a, t_masteronly_volatile.b, t_masteronly_volatile.c
 Optimizer: Postgres query optimizer
 Settings: enable_seqscan=off
(22 rows)

-- targetlist
explain (costs off) select * from t_hashdist cross join (select random () from t_masteronly_volatile)x;
                        QUERY PLAN                         
-----------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice2)
                     ->  Seq Scan on t_masteronly_volatile
 Optimizer: Postgres query optimizer
(7 rows)

explain (costs off) select * from t_hashdist cross join (select a, sum(random()) from t_masteronly_volatile group by a) x;
                              QUERY PLAN                               
-----------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice2)
                     ->  GroupAggregate
                           Group Key: t_masteronly_volatile.a
                           ->  Sort
                                 Sort Key: t_masteronly_volatile.a
                                 ->  Seq Scan on t_masteronly_volatile
 Optimizer: Postgres query optimizer
(11 rows)

explain (costs off) select * from t_hashdist cross join (select random() as k, sum(a) from t_masteronly_volatile group by k) x;
                              QUERY PLAN                               
-----------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice2)
                     ->  GroupAggregate
                           Group Key: (random())
                           ->  Sort
                                 Sort Key: (random())
                                 ->  Seq Scan on t_masteronly_volatile
 Optimizer: Postgres query optimizer
(11 rows)

explain (costs off) select * from t_hashdist cross join (select a, sum(b) as s from t_masteronly_volatile group by a having sum(b) > random() order by a) x ;
                                           QUERY PLAN                                            
-------------------------------------------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice2)
                     ->  GroupAggregate
                           Group Key: t_masteronly_volatile.a
                           Filter: ((sum(t_masteronly_volatile.b))::double precision > random())
                           ->  Sort
                                 Sort Key: t_masteronly_volatile.a
                                 ->  Seq Scan on t_masteronly_volatile
 Optimizer: Postgres query optimizer
(12 rows)

-- insert
explain (costs off) insert into t_masteronly_volatile select random() from t_masteronly_volatile;
                              QUERY PLAN                               
-----------------------------------------------------------------------
 Insert on t_masteronly_volatile
   ->  Subquery Scan on "*SELECT*"
         ->  Seq Scan on t_masteronly_volatile t_masteronly_volatile_1
 Optimizer: Postgres query optimizer
(4 rows)

explain (costs off) insert into t_masteronly_volatile select random(), a, a from generate_series(1, 10) a;
                   QUERY PLAN                   
------------------------------------------------
 Insert on t_masteronly_volatile
   ->  Subquery Scan on "*SELECT*"
         ->  Function Scan on generate_series a
 Optimizer: Postgres query optimizer
(4 rows)

create sequence seq_for_insert_masteronly_table;
explain (costs off) insert into t_masteronly_volatile select nextval('seq_for_insert_masteronly_table');
             QUERY PLAN              
-------------------------------------
 Insert on t_masteronly_volatile
   ->  Subquery Scan on "*SELECT*"
         ->  Result
 Optimizer: Postgres query optimizer
(4 rows)

-- update & delete
explain (costs off) update t_masteronly_volatile set a = 1 where b > random();
                     QUERY PLAN                     
----------------------------------------------------
 Update on t_masteronly_volatile
   ->  Seq Scan on t_masteronly_volatile
         Filter: ((b)::double precision > random())
 Optimizer: Postgres query optimizer
(4 rows)

explain (costs off) update t_masteronly_volatile set a = 1 from t_masteronly_volatile x where x.a + random() = t_masteronly_volatile.b;
                                                QUERY PLAN                                                 
-----------------------------------------------------------------------------------------------------------
 Update on t_masteronly_volatile
   ->  Nested Loop
         Join Filter: (((x.a)::double precision + random()) = (t_masteronly_volatile.b)::double precision)
         ->  Seq Scan on t_masteronly_volatile
         ->  Materialize
               ->  Seq Scan on t_masteronly_volatile x
 Optimizer: Postgres query optimizer
(7 rows)

explain (costs off) update t_masteronly_volatile set a = 1 from t_hashdist x where x.a + random() = t_masteronly_volatile.b;
                                                   QUERY PLAN                                                    
-----------------------------------------------------------------------------------------------------------------
 Update on t_masteronly_volatile
   ->  Gather Motion 3:1  (slice1; segments: 3)
         ->  Nested Loop
               Join Filter: (((x.a)::double precision + random()) = (t_masteronly_volatile.b)::double precision)
               ->  Seq Scan on t_hashdist x
               ->  Materialize
                     ->  Broadcast Motion 1:3  (slice2)
                           ->  Seq Scan on t_masteronly_volatile
 Optimizer: Postgres query optimizer
(9 rows)

explain (costs off) delete from t_masteronly_volatile where a < random();
                     QUERY PLAN                     
----------------------------------------------------
 Delete on t_masteronly_volatile
   ->  Seq Scan on t_masteronly_volatile
         Filter: ((a)::double precision < random())
 Optimizer: Postgres query optimizer
(4 rows)

explain (costs off) delete from t_masteronly_volatile using t_masteronly_volatile x where t_masteronly_volatile.a + x.b < random();
                                      QUERY PLAN                                       
---------------------------------------------------------------------------------------
 Delete on t_masteronly_volatile
   ->  Nested Loop
         Join Filter: (((t_masteronly_volatile.a + x.b))::double precision < random())
         ->  Seq Scan on t_masteronly_volatile
         ->  Materialize
               ->  Seq Scan on t_masteronly_volatile x
 Optimizer: Postgres query optimizer
(7 rows)

explain (costs off) update t_masteronly_volatile set a = random();
               QUERY PLAN                
-----------------------------------------
 Update on t_masteronly_volatile
   ->  Seq Scan on t_masteronly_volatile
 Optimizer: Postgres query optimizer
(3 rows)

-- limit
explain (costs off) insert into t_masteronly_volatile select * from t_masteronly_volatile limit random();
                              QUERY PLAN                               
-----------------------------------------------------------------------
 Insert on t_masteronly_volatile
   ->  Limit
         ->  Seq Scan on t_masteronly_volatile t_masteronly_volatile_1
 Optimizer: Postgres query optimizer
(4 rows)

explain (costs off) select * from t_hashdist cross join (select * from t_masteronly_volatile limit random()) x;
                           QUERY PLAN                            
-----------------------------------------------------------------
 Gather Motion 3:1  (slice1; segments: 3)
   ->  Nested Loop
         ->  Seq Scan on t_hashdist
         ->  Materialize
               ->  Broadcast Motion 1:3  (slice2)
                     ->  Limit
                           ->  Seq Scan on t_masteronly_volatile
 Optimizer: Postgres query optimizer
(8 rows)

-- copy
CREATE TEMP TABLE x (
	a serial,
	b int,
	c text not null default 'stuff',
	d text,
	e text
) DISTRIBUTED MASTERONLY;
COPY x (a, b, c, d, e) from stdin;
COPY x (b, d) from stdin;
COPY x (b, d) from stdin;
COPY x (a, b, c, d, e) from stdin;
-- non-existent column in column list: should fail
COPY x (xyz) from stdin;
ERROR:  column "xyz" of relation "x" does not exist
-- too many columns in column list: should fail
COPY x (a, b, c, d, e, d, c) from stdin;
ERROR:  column "d" specified more than once
-- missing data: should fail
COPY x from stdin;
ERROR:  invalid input syntax for type integer: ""
CONTEXT:  COPY x, line 1, column a: ""
COPY x from stdin;
ERROR:  missing data for column "e"
CONTEXT:  COPY x, line 1: "2000	230	23	23"
COPY x from stdin;
ERROR:  missing data for column "e"
CONTEXT:  COPY x, line 1: "2001	231	\N	\N"
-- extra data: should fail
COPY x from stdin;
ERROR:  extra data after last expected column
CONTEXT:  COPY x, line 1: "2002	232	40	50	60	70	80"
-- check results of copy in
SELECT * FROM x;
   a   | b  |   c   |   d    | e  
-------+----+-------+--------+----
  9999 |    | \N    | NN     | 
 10000 | 21 | 31    | 41     | 51
     1 |  1 | stuff | test_1 | 
     2 |  2 | stuff | test_2 | 
     3 |  3 | stuff | test_3 | 
     4 |  4 | stuff | test_4 | 
     5 |  5 | stuff | test_5 | 
 10001 | 22 | 32    | 42     | 52
 10002 | 23 | 33    | 43     | 53
 10003 | 24 | 34    | 44     | 54
 10004 | 25 | 35    | 45     | 55
 10005 | 26 | 36    | 46     | 56
(12 rows)

-- check copy out
COPY x TO stdout;
9999	\N	\\N	NN	\N
10000	21	31	41	51
1	1	stuff	test_1	\N
2	2	stuff	test_2	\N
3	3	stuff	test_3	\N
4	4	stuff	test_4	\N
5	5	stuff	test_5	\N
10001	22	32	42	52
10002	23	33	43	53
10003	24	34	44	54
10004	25	35	45	55
10005	26	36	46	56
COPY x (c, e) TO stdout;
\\N	\N
31	51
stuff	\N
stuff	\N
stuff	\N
stuff	\N
stuff	\N
32	52
33	53
34	54
35	55
36	56
COPY x (b, e) TO stdout WITH NULL 'I''m null';
I'm null	I'm null
21	51
1	I'm null
2	I'm null
3	I'm null
4	I'm null
5	I'm null
22	52
23	53
24	54
25	55
26	56
CREATE TEMP TABLE y (
	col1 text,
	col2 text
) DISTRIBUTED MASTERONLY;
INSERT INTO y VALUES ('Jackson, Sam', E'\\h');
INSERT INTO y VALUES ('It is "perfect".',E'\t');
INSERT INTO y VALUES ('', NULL);
COPY y TO stdout WITH CSV;
"Jackson, Sam",\h
"It is ""perfect"".",	
"",
COPY y TO stdout WITH CSV QUOTE '''' DELIMITER '|';
Jackson, Sam|\h
It is "perfect".|	
''|
COPY y TO stdout WITH CSV FORCE QUOTE col2 ESCAPE E'\\' ENCODING 'sql_ascii';
"Jackson, Sam","\\h"
"It is \"perfect\".","	"
"",
COPY y TO stdout WITH CSV FORCE QUOTE *;
"Jackson, Sam","\h"
"It is ""perfect"".","	"
"",
-- Repeat above tests with new 9.0 option syntax
COPY y TO stdout (FORMAT CSV);
"Jackson, Sam",\h
"It is ""perfect"".",	
"",
COPY y TO stdout (FORMAT CSV, QUOTE '''', DELIMITER '|');
Jackson, Sam|\h
It is "perfect".|	
''|
COPY y TO stdout (FORMAT CSV, FORCE_QUOTE (col2), ESCAPE E'\\');
"Jackson, Sam","\\h"
"It is \"perfect\".","	"
"",
COPY y TO stdout (FORMAT CSV, FORCE_QUOTE *);
"Jackson, Sam","\h"
"It is ""perfect"".","	"
"",
\copy y TO stdout (FORMAT CSV)
"Jackson, Sam",\h
"It is ""perfect"".",	
"",
\copy y TO stdout (FORMAT CSV, QUOTE '''', DELIMITER '|')
Jackson, Sam|\h
It is "perfect".|	
''|
\copy y TO stdout (FORMAT CSV, FORCE_QUOTE (col2), ESCAPE E'\\')
"Jackson, Sam","\\h"
"It is \"perfect\".","	"
"",
\copy y TO stdout (FORMAT CSV, FORCE_QUOTE *)
"Jackson, Sam","\h"
"It is ""perfect"".","	"
"",
--test that we read consecutive LFs properly
CREATE TEMP TABLE testnl (a int, b text, c int) DISTRIBUTED MASTERONLY;
COPY testnl FROM stdin CSV;
-- test end of copy marker
CREATE TEMP TABLE testeoc (a text) DISTRIBUTED MASTERONLY;
COPY testeoc FROM stdin CSV;
COPY testeoc TO stdout CSV;
a\.
\.b
c\.d
"\."
-- test handling of nonstandard null marker that violates escaping rules
CREATE TEMP TABLE testnull(a int, b text) DISTRIBUTED MASTERONLY;
INSERT INTO testnull VALUES (1, E'\\0'), (NULL, NULL);
COPY testnull TO stdout WITH NULL AS E'\\0';
1	\\0
\0	\0
COPY testnull FROM stdin WITH NULL AS E'\\0';
SELECT * FROM testnull;
 a  | b  
----+----
  1 | \0
    | 
 42 | \0
    | 
(4 rows)

BEGIN;
CREATE TABLE vistest (LIKE testeoc) DISTRIBUTED MASTERONLY;
COPY vistest FROM stdin CSV;
COMMIT;
SELECT * FROM vistest;
 a  
----
 a0
 b
(2 rows)

BEGIN;
TRUNCATE vistest;
COPY vistest FROM stdin CSV;
SELECT * FROM vistest;
 a  
----
 a1
 b
(2 rows)

SAVEPOINT s1;
TRUNCATE vistest;
COPY vistest FROM stdin CSV;
SELECT * FROM vistest;
 a  
----
 d1
 e
(2 rows)

COMMIT;
SELECT * FROM vistest;
 a  
----
 d1
 e
(2 rows)

BEGIN;
TRUNCATE vistest;
COPY vistest FROM stdin CSV FREEZE;
SELECT * FROM vistest;
 a  
----
 a2
 b
(2 rows)

SAVEPOINT s1;
TRUNCATE vistest;
COPY vistest FROM stdin CSV FREEZE;
SELECT * FROM vistest;
 a  
----
 d2
 e
(2 rows)

COMMIT;
SELECT * FROM vistest;
 a  
----
 d2
 e
(2 rows)

BEGIN;
TRUNCATE vistest;
COPY vistest FROM stdin CSV FREEZE;
SELECT * FROM vistest;
 a 
---
 x
 y
(2 rows)

COMMIT;
TRUNCATE vistest;
COPY vistest FROM stdin CSV FREEZE;
ERROR:  cannot perform COPY FREEZE because the table was not created or truncated in the current subtransaction
BEGIN;
TRUNCATE vistest;
SAVEPOINT s1;
COPY vistest FROM stdin CSV FREEZE;
ERROR:  cannot perform COPY FREEZE because the table was not created or truncated in the current subtransaction
COMMIT;
BEGIN;
INSERT INTO vistest VALUES ('z');
SAVEPOINT s1;
TRUNCATE vistest;
ROLLBACK TO SAVEPOINT s1;
COPY vistest FROM stdin CSV FREEZE;
ERROR:  cannot perform COPY FREEZE because the table was not created or truncated in the current subtransaction
COMMIT;
CREATE FUNCTION truncate_in_subxact() RETURNS VOID AS
$$
BEGIN
	TRUNCATE vistest;
EXCEPTION
  WHEN OTHERS THEN
	INSERT INTO vistest VALUES ('subxact failure');
END;
$$ language plpgsql;
BEGIN;
INSERT INTO vistest VALUES ('z');
SELECT truncate_in_subxact();
 truncate_in_subxact 
---------------------
 
(1 row)

COPY vistest FROM stdin CSV FREEZE;
SELECT * FROM vistest;
 a  
----
 d4
 e
(2 rows)

COMMIT;
SELECT * FROM vistest;
 a  
----
 d4
 e
(2 rows)

-- Test FORCE_NOT_NULL and FORCE_NULL options
CREATE TEMP TABLE forcetest (
    a INT NOT NULL,
    b TEXT NOT NULL,
    c TEXT,
    d TEXT,
    e TEXT
) DISTRIBUTED MASTERONLY;
\pset null NULL
-- should succeed with no effect ("b" remains an empty string, "c" remains NULL)
BEGIN;
COPY forcetest (a, b, c) FROM STDIN WITH (FORMAT csv, FORCE_NOT_NULL(b), FORCE_NULL(c));
COMMIT;
SELECT b, c FROM forcetest WHERE a = 1;
 b |  c   
---+------
   | NULL
(1 row)

-- should succeed, FORCE_NULL and FORCE_NOT_NULL can be both specified
BEGIN;
COPY forcetest (a, b, c, d) FROM STDIN WITH (FORMAT csv, FORCE_NOT_NULL(c,d), FORCE_NULL(c,d));
COMMIT;
SELECT c, d FROM forcetest WHERE a = 2;
 c |  d   
---+------
   | NULL
(1 row)

-- should fail with not-null constraint violation
BEGIN;
COPY forcetest (a, b, c) FROM STDIN WITH (FORMAT csv, FORCE_NULL(b), FORCE_NOT_NULL(c));
ERROR:  null value in column "b" violates not-null constraint
DETAIL:  Failing row contains (3, null, , null, null).
CONTEXT:  COPY forcetest, line 1: "3,,"""
ROLLBACK;
-- should fail with "not referenced by COPY" error
BEGIN;
COPY forcetest (d, e) FROM STDIN WITH (FORMAT csv, FORCE_NOT_NULL(b));
ERROR:  FORCE_NOT_NULL column "b" not referenced by COPY
ROLLBACK;
-- should fail with "not referenced by COPY" error
BEGIN;
COPY forcetest (d, e) FROM STDIN WITH (FORMAT csv, FORCE_NULL(b));
ERROR:  FORCE_NULL column "b" not referenced by COPY
ROLLBACK;
\pset null ''
-- should fail with "masteronly_range_partition is DISTRIBUTED MASTERONLY, cannot set PARTITION."
CREATE TABLE masteronly_range_partition (id int, date date)
DISTRIBUTED MASTERONLY
PARTITION BY RANGE(date)
(
START (date '2020-01-01')
END (date '2021-01-01')
EVERY (INTERVAL '1 day')
);
ERROR:  masteronly_range_partition is DISTRIBUTED MASTERONLY, cannot set PARTITION.
-- should fail with "masteronly_list_partition is DISTRIBUTED MASTERONLY, cannot set PARTITION."
CREATE TABLE masteronly_list_partition (id int, rank int, year int, gender
char(1), count int )
DISTRIBUTED MASTERONLY
PARTITION BY LIST (gender)
( PARTITION girls VALUES ('F'),
  PARTITION boys VALUES ('M'),
  DEFAULT PARTITION other );
ERROR:  masteronly_list_partition is DISTRIBUTED MASTERONLY, cannot set PARTITION.
CREATE TABLE expand_masteronly (id int)
DISTRIBUTED MASTERONLY;
-- should fail with "cannot expand table "foo" "MASTERONLY table does not support expansion."
ALTER TABLE expand_masteronly EXPAND TABLE;
ERROR:  cannot expand table "expand_masteronly"
DETAIL:  MASTERONLY table does not support expansion.
-- start_ignore
drop schema masteronly cascade;
NOTICE:  drop cascades to 14 other objects
DETAIL:  drop cascades to table parent_part
drop cascades to table foo
drop cascades to table bar
drop cascades to view v_foo
drop cascades to table baz
drop cascades to table qux
drop cascades to table cursor_update
drop cascades to table minmaxtest
drop cascades to table t_hashdist
drop cascades to table t_masteronly_volatile
drop cascades to sequence seq_for_insert_masteronly_table
drop cascades to table vistest
drop cascades to function truncate_in_subxact()
drop cascades to table expand_masteronly
-- end_ignore
